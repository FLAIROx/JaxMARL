# pqn_vdn_ff is suggested for MPE (faster and good enough), but pqn_vdn_rnn is also available
"TOTAL_TIMESTEPS": 1e7
"NUM_ENVS": 128
"MEMORY_WINDOW": 4
"NUM_STEPS": 128
"HIDDEN_SIZE": 128
"NUM_LAYERS": 2
"NORM_INPUT": False
"NORM_TYPE": "layer_norm"
"EPS_START": 1.0
"EPS_FINISH": 0.01
"EPS_DECAY": 0.1
"MAX_GRAD_NORM": 1
"NUM_MINIBATCHES": 8
"NUM_EPOCHS": 4
"LR": 0.00025
"LR_LINEAR_DECAY": True
"GAMMA": 0.99
"LAMBDA": 0.85
#"REW_SCALE": 10. # scale the reward to the original scale of SMAC

# ENV
"ENV_NAME": "utracking"
"ENV_KWARGS": {
  "num_agents": 3,
  "num_landmarks": 3,
  "prop_range_landmark": [0],
  "dt": 30,
  "min_init_distance": 30,
  "max_init_distance": 100,
}

# evaluate
"TEST_DURING_TRAINING": True
"TEST_INTERVAL": 0.05 # as a fraction of updates, i.e. log every 5% of training process
"TEST_NUM_STEPS": 128
"TEST_NUM_ENVS": 512 # number of episodes to average over, can affect performance

"ALG_NAME": "pqn_vdn_rnn_3v3_nomoving" # if you want to change the name of the algo in the metrics