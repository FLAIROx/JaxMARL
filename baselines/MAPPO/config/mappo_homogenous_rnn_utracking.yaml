"LR": 0.0005
"NUM_ENVS": 128
"NUM_STEPS": 128
"TOTAL_TIMESTEPS": 1e8
"FC_DIM_SIZE": 256
"GRU_HIDDEN_DIM": 256
"NUM_LAYERS": 4
"UPDATE_EPOCHS": 4
"NUM_MINIBATCHES": 4
"GAMMA": 0.99
"GAE_LAMBDA": 0.95
"CLIP_EPS": 0.2
"SCALE_CLIP_EPS": False
"ENT_COEF": 0.01
"VF_COEF": 0.5
"KL_COEFF": 0.
"MAX_GRAD_NORM": 0.5
"ACTIVATION": "relu"
"ANNEAL_LR": True

# ENV
"ENV_NAME": "utracking"
"ENV_KWARGS": {
  "num_agents": 2,
  "num_landmarks": 2,
  "max_steps": 256,
  "difficulty": "easy",
  "rew_follow_coeff": 1.0, # coefficient for the following reward
  "rew_tracking_coeff": 0.0, # coefficient for the tracking reward
  "steps_for_new_range": 1, # recieve a new range measurement every n steps, more realistic is 4 (but more difficult)
  "steps_for_agent_communication": 1, # agents can communicate every n steps, more realistic is 6 (but more difficult)
  "pre_init_pos_len": 10000000, # pre-generate initial positions to speed up resets
}

# EXP
"SEED": 0
"NUM_SEEDS": 1
"TUNE": False
"SAVE_PATH": # path
"LOAD_PATH": # path
"LOAD_CRITIC": #True  
"ALG_NAME": "mappo_rnn_follow"
"CHECKPOINT_INTERVAL": # 0.05 # perecentage of total update steps
"ANIMATION_LOG_INTERVAL": 0.1  # percentage of total update steps
"ANIMATION_MAX_STEPS": 256 # should be the same of the env

# WANDB
"WANDB_MODE": disabled
"ENTITY": 
"PROJECT": 
"WANDB_LOG_ALL_SEEDS": False


