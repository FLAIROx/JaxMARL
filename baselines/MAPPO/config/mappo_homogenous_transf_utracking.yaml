LR: 0.0005
NUM_ENVS: 128
NUM_STEPS: 256
TOTAL_TIMESTEPS: 1e8
HIDDEN_DIM: 64
NUM_LAYERS: 2
NUM_HEADS: 8
FF_DIM: 128
UPDATE_EPOCHS: 4
NUM_MINIBATCHES: 4
GAMMA: 0.99
GAE_LAMBDA: 0.95
CLIP_EPS: 0.2
SCALE_CLIP_EPS: false
ENT_COEF: 0.01
VF_COEF: 0.5
MAX_GRAD_NORM: 0.5
ACTIVATION: relu
ANNEAL_LR: true

# Environment configuration
"ENV_NAME": "utracking"
"ENV_KWARGS": {
  "num_agents": 2,
  "num_landmarks": 2,
  "max_steps": 256,
  "difficulty": "easy",
  "rew_follow_coeff": 1.0, # coefficient for the following reward
  "rew_tracking_coeff": 0.0, # coefficient for the tracking reward
  "steps_for_new_range": 1, # recieve a new range measurement every n steps, more realistic is 4 (but more difficult)
  "steps_for_agent_communication": 1, # agents can communicate every n steps, more realistic is 6 (but more difficult)
  "matrix_obs": true, # use matrix observation for transformers
  "matrix_state": true, # use matrix state for transformers
  "pre_init_pos_len": 10000000, # pre-generate initial positions to speed up resets
}
 

# Experiment settings
SEED: 0
NUM_SEEDS: 1
TUNE: false
SAVE_PATH: # path
LOAD_PATH: # path
LOAD_CRITIC: #True
ALG_NAME: mappo_transformer
CHECKPOINT_INTERVAL: 0.05 # perecentage of total update steps
ANIMATION_LOG_INTERVAL: 0.1  # percentage of total update steps
ANIMATION_MAX_STEPS: 256     # should match the env

# Weights & Biases logging
WANDB_MODE: disabled
ENTITY: 
PROJECT: 
WANDB_LOG_ALL_SEEDS: false